TITLE: Thematic analysis

Thematic analysis is one of the most common forms of analysis within qualitative research. It emphasizes identifying, analysing and interpreting patterns of meaning (or "themes") within qualitative data. Thematic analysis is often understood as a method or technique in contrast to most other qualitative analytic approaches – such as grounded theory, discourse analysis, narrative analysis and interpretative phenomenological analysis – which can be described as methodologies or theoretically informed frameworks for research (they specify guiding theory, appropriate research questions and methods of data collection, as well as procedures for conducting analysis). Thematic analysis is best thought of as an umbrella term for a variety of different approaches, rather than a singular method. Different versions of thematic analysis are underpinned by different philosophical and conceptual assumptions and are divergent in terms of procedure. Leading thematic analysis proponents, psychologists Virginia Braun and Victoria Clarke distinguish between three main types of thematic analysis: coding reliability approaches (examples include the approaches developed by Richard Boyatzis and Greg Guest and colleagues), code book approaches (these include approaches like framework analysis,  template analysis and matrix analysis) and reflexive approaches. They first described their own widely used approach in 2006 in the journal Qualitative Research in Psychology as reflexive thematic analysis. This paper has over 120,000 Google Scholar citations and according to Google Scholar is the most cited academic paper published in 2006. The popularity of this paper exemplifies the growing interest in thematic analysis as a distinct method (although some have questioned whether it is a distinct method or simply a generic set of analytic procedures).


== Description ==
Thematic analysis is used in qualitative research and focuses on examining themes or patterns of meaning within data. This method can emphasize both organization and rich description of the data set and theoretically informed interpretation of meaning. Thematic analysis goes beyond simply counting phrases or words in a text (as in content analysis) and explores explicit and implicit meanings within the data. Coding is the primary process for developing themes by identifying items of analytic interest in the data and tagging these with a coding label. In some thematic analysis approaches coding follows theme development and is a deductive process of allocating data to pre-identified themes (this approach is common in coding reliability and code book approaches), in other approaches – notably Braun and Clarke's reflexive approach – coding precedes theme development and themes are built from codes. One of the hallmarks of thematic analysis is its flexibility – flexibility with regards to framing theory, research questions and research design. Thematic analysis can be used to explore questions about participants' lived experiences, perspectives, behaviour and practices, the factors and social processes that influence and shape particular phenomena, the explicit and implicit norms and 'rules' governing particular practices, as well as the social construction of meaning and the representation of social objects in particular texts and contexts. 
Thematic analysis can be used to analyse most types of qualitative data including qualitative data collected from interviews, focus groups, surveys, solicited diaries, visual methods, observation and field research, action research, memory work, vignettes, story completion and secondary sources. Data-sets can range from short, perfunctory response to an open-ended survey question to hundreds of pages of interview transcripts. Thematic analysis can be used to analyse both small and large data-sets. Thematic analysis is often used in mixed-method designs – the theoretical flexibility of TA makes it a more straightforward choice than approaches with specific embedded theoretical assumptions.
Thematic analysis is sometimes claimed to be compatible with phenomenology in that it can focus on participants' subjective experiences and sense-making; there is a long tradition of using thematic analysis in phenomenological research. A phenomenological approach emphasizes the participants' perceptions, feelings and experiences as the paramount object of study. Rooted in humanistic psychology, phenomenology notes giving voice to the "other" as a key component in qualitative research in general. This approach allows the respondents to discuss the topic in their own words, free of constraints from fixed-response questions found in quantitative studies.
Thematic analysis is sometimes erroneously assumed to be only compatible with phenomenology or experiential approaches to qualitative research. Braun and Clarke argue that their reflexive approach is equally compatible with social constructionist, poststructuralist and critical approaches to qualitative research. They emphasise the theoretical flexibility of thematic analysis and its use within realist, critical realist and relativist ontologies and positivist, contextualist and constructionist epistemologies.
Like most research methods, the process of thematic analysis of data can occur both inductively or deductively. In an inductive approach, the themes identified are strongly linked to the data. This means that the process of coding occurs without trying to fit the data into pre-existing theory or framework. But inductive learning processes in practice are rarely 'purely bottom up'; it is not possible for the researchers and their communities to free themselves completely from ontological (theory of reality), epistemological (theory of knowledge) and paradigmatic (habitual) assumptions – coding will always to some extent reflect the researcher's philosophical standpoint, and individual/communal values with respect to knowledge and learning. Deductive approaches, on the other hand, are more theory-driven. This form of analysis tends to be more interpretative because analysis is explicitly shaped and informed by pre-existing theory and concepts (ideally cited for transparency in the shared learning). Deductive approaches can involve seeking to identify themes identified in other research in the data-set or using existing theory as a lens through which to organise, code and interpret the data. Sometimes deductive approaches are misunderstood as coding driven by a research question or the data collection questions. A thematic analysis can also combine inductive and deductive approaches, for example in foregrounding interplay between a priori ideas from clinician-led qualitative data analysis teams and those emerging from study participants and the field observations.


== Different approaches ==
Coding reliability approaches have the longest history and are often little different from qualitative content analysis. As the name suggests they prioritise the measurement of coding reliability through the use of structured and fixed code books, the use of multiple coders who work independently to apply the code book to the data, the measurement of inter-rater reliability or inter-coder agreement (typically using Cohen's kappa) and the determination of final coding through consensus or agreement between coders. These approaches are a form of qualitative positivism or small q qualitative research, which combine the use of qualitative data with data analysis processes and procedures based on the research values and assumptions of (quantitative) positivism – emphasising the importance of establishing coding reliability and viewing researcher subjectivity or 'bias' as a potential threat to coding reliability that must be contained and 'controlled for' to avoiding confounding the 'results' (with the presence and active influence of the researcher). Boyatzis presents his approach as one that can 'bridge the divide' between quantitative (positivist) and qualitative (interpretivist) paradigms. Some qualitative researchers are critical of the use of structured code books, multiple independent coders and inter-rater reliability measures. Janice Morse argues that such coding is necessarily coarse and superficial to facilitate coding agreement. Braun and Clarke (citing Yardley) argue that all coding agreement demonstrates is that coders have been trained to code in the same way not that coding is 'reliable' or 'accurate' with respect to the underlying phenomena that is coded and described.
Code book approaches like framework analysis, template analysis and matrix analysis centre on the use of structured code books but – unlike coding reliability approaches – emphasise to a greater or lesser extent qualitative research values. Both coding reliability and code book approaches typically involve early theme development – with all or some themes developed prior to coding, often following some data familiarisation (reading and re-reading data to become intimately familiar with its contents). Once themes have been developed the code book is created – this might involve some initial analysis of a portion of or all of the data. The data is then coded. Coding involves allocating data to the pre-determined themes using the code book as a guide. The code book can also be used to map and display the occurrence of codes and themes in each data item. Themes are often of the shared topic type discussed by Braun and Clarke.
Reflexive approaches centre organic and flexible coding processes – there is no code book, coding can be undertaken by one researcher, if multiple researchers are involved in coding this is conceptualised as a collaborative process rather than one that should lead to consensus. Individual codes are not fixed – they can evolve throughout the coding process, the boundaries of the code can be redrawn, codes can be split into two or more codes, collapsed with other codes and even promoted to themes. Reflexive approaches typically involve later theme development – with themes created from clustering together similar codes. Themes should capture shared meaning organised around a central concept or idea.
Braun and Clarke and colleagues have been critical of a tendency to overlook the diversity within thematic analysis and the failure to recognise the differences between the various approaches they have mapped out. They argue that this failure leads to unthinking 'mash-ups' of their approach with incompatible techniques and approaches such as code books, consensus coding and measurement of inter-rater reliability.


== Theme ==
There is no one definition or conceptualisation of a theme in thematic analysis. For some thematic analysis proponents, including Braun and Clarke, themes are conceptualised as patterns of shared meaning across data items, underpinned or united by a central concept, which are important to the understanding of a phenomenon and are relevant to the research question. For others (including most coding reliability and code book proponents), themes are simply summaries of information related to a particular topic or data domain; there is no requirement for shared meaning organised around a central concept, just a shared topic. Although these two conceptualisations are associated with particular approaches to thematic analysis, they are often confused and conflated. What Braun and Clarke call domain summary or topic summary themes often have one word theme titles (e.g. Gender, Support) or titles like 'Benefits of...', 'Barriers to...' signalling the focus on summarising everything participants said, or the main points raised, in relation to a particular topic or data domain. Topic summary themes are typically developed prior to data coding and often reflect data collection questions. Shared meaning themes that are underpinned by a central concept or idea cannot be developed prior to coding (because they are built from codes), so are the output of a thorough and systematic coding process. Braun and Clarke have been critical of the confusion of topic summary themes with their conceptualisation of themes as capturing shared meaning underpinned by a central concept. Some qualitative researchers have argued that topic summaries represent an under-developed analysis or analytic foreclosure.
There is controversy around the notion that 'themes emerge' from data. Braun and Clarke are critical of this language because they argue it positions themes as entities that exist fully formed in data – the researcher is simply a passive witness to the themes 'emerging' from the data. Instead they argue that the researcher plays an active role in the creation of themes – so themes are constructed, created, generated rather than simply emerging. Others use the term deliberatively to capture the inductive (emergent) creation of themes. However, it is not always clear how the term is being used.
Prevalence or recurrence is not necessarily the most important criteria in determining what constitutes a theme; themes can be considered important if they are highly relevant to the research question and significant in understanding the phenomena of interest.  Theme prevalence does not necessarily mean the frequency at which a theme occurs (i.e. the number of data items in which it occurs); it can also mean how much data a theme captures within each data item and across the data-set. Themes are typically evident across the data set, but a higher frequency does not necessarily mean that the theme is more important to understanding the data. A researcher's judgement is the key tool in determining which themes are more crucial.
There are also different levels at which data can be coded and themes can be identified – semantic and latent. A thematic analysis can focus on one of these levels or both. Semantic codes and themes identify the explicit and surface meanings of the data. The researcher does not look beyond what the participant said or wrote. Conversely, latent codes or themes capture underlying ideas, patterns, and assumptions. This requires a more interpretative and conceptual orientation to the data.
For Braun and Clarke, there is a clear (but not absolute) distinction between a theme and a code – a code captures one (or more) insights about the data and a theme encompasses numerous insights organised around a central concept or idea. They often use the analogy of a brick and tile house – the code is an individual brick or tile, and themes are the walls or roof panels, each made up of numerous codes. Other approaches to thematic analysis do not make such a clear distinction between codes and themes – several texts recommend that researchers "code for themes". This can be confusing because for Braun and Clarke, and others, the theme is considered the outcome or result of coding, not that which is coded. In approaches that make a clear distinction between codes and themes, the code is the label that is given to particular pieces of the data that contributes to a theme. For example, "SECURITY can be a code, but A FALSE SENSE OF SECURITY can be a theme."


== Methodological issues ==


=== Reflexivity journals ===
Given that qualitative work is inherently interpretive research, the positionings, values, and judgments of the researchers need to be explicitly acknowledged so they are taken into account in making sense of the final report and judging its quality. This type of openness and reflection is considered to be positive in the qualitative community. Researchers shape the work that they do and are the instrument for collecting and analyzing data. In order to acknowledge the researcher as the tool of analysis, it is useful to create and maintain a reflexivity journal.
The reflexivity process can be described as the researcher reflecting on and documenting how their values, positionings, choices and research practices influenced and shaped the study and the final analysis of the data. Reflexivity journals are somewhat similar to the use of analytic memos or memo writing in grounded theory, which can be useful for reflecting on the developing analysis and potential patterns, themes and concepts. Throughout the coding process researchers should have detailed records of the development of each of their codes and potential themes. In addition, changes made to themes and connections between themes can be discussed in the final report to assist the reader in understanding decisions that were made throughout the coding process.
Once data collection is complete and researchers begin the data analysis phases, they should make notes on their initial impressions of the data. The logging of ideas for future analysis can aid in getting thoughts and reflections written down and may serve as a reference for potential coding ideas as one progresses from one phase to the next in the thematic analysis process.


=== Coding practice ===
Questions to consider whilst coding may include:

What are people doing? What are they trying to accomplish?
How exactly do they do this? What specific means or strategies are used?
How do people talk about and understand what is going on?
What assumptions are they making?
What do I see going on here? What did I learn from note taking?
Why did I include them?
Such questions are generally asked throughout all cycles of the coding process and the data analysis. A reflexivity journal is often used to identify potential codes that were not initially pertinent to the study.


=== Sample size considerations ===
There is no straightforward answer to questions of sample size in thematic analysis; just as there is no straightforward answer to sample size in qualitative research more broadly (the classic answer is 'it depends' – on the scope of the study, the research question and topic, the method or methods of data collection, the richness of individual data items, the analytic approach). Some coding reliability and code book proponents provide guidance for determining sample size in advance of data analysis – focusing on the concept of saturation or information redundancy (no new information, codes or themes are evident in the data). These attempts to 'operationalise' saturation suggest that code saturation (often defined as identifying one instances of a code) can be achieved in as few as 12 or even 6 interviews in some circumstances. Meaning saturation – developing a "richly textured" understanding of issues – is thought to require larger samples (at least 24 interviews). There are numerous critiques of the concept of data saturation – many argue it is embedded within a realist conception of fixed meaning and in a qualitative paradigm there is always potential for new understandings because of the researcher's role in interpreting meaning. Some quantitative researchers have offered statistical models for determining sample size in advance of data collection in thematic analysis. For example, Fugard and Potts offered a prospective, quantitative tool to support thinking on sample size by analogy to quantitative sample size estimation methods. Lowe and colleagues proposed quantitative, probabilistic measures of degree of saturation that can be calculated from an initial sample and used to estimate the sample size required to achieve a specified level of saturation. Their analysis indicates that commonly used binomial sample size estimation methods may significantly underestimate the sample size required for saturation. All of these tools have been criticised by qualitative researchers (including Braun and Clarke) for relying on assumptions about qualitative research, thematic analysis and themes that are antithetical to approaches that prioritise qualitative research values.


== Braun and Clarke's six phases of thematic analysis ==


=== Phase 1: Becoming familiar with the data ===
This six-phase process for thematic analysis is based on the work of Braun and Clarke and their reflexive approach to thematic analysis. This six phase cyclical process involves going back and forth between phases of data analysis as needed until the researchers are satisfied with the final themes. Researchers conducting thematic analysis should attempt to go beyond surface meanings of the data to make sense of the data and tell a rich and compelling story about what the data means. The procedures associated with other thematic analysis approaches are rather different. This description of Braun and Clarke's six phase process also includes some discussion of the contrasting insights provided by other thematic analysis proponents. The initial phase in reflexive thematic analysis is common to most approaches – that of data familiarisation. This is where researchers familiarize themselves with the content of their data – both the detail of each data item and the 'bigger picture'. In other approaches, prior to reading the data, researchers may create a "start list" of potential codes. As Braun and Clarke's approach is intended to focus on the data and not the researcher's prior conceptions they only recommend developing codes prior to familiarisation in deductive approaches where coding is guided by pre-existing theory. For Miles and Huberman, in their matrix approach, "start codes" should be included in a reflexivity journal with a description of representations of each code and where the code is established. Analyzing data in an active way will assist researchers in searching for meanings and patterns in the data set. At this stage, it is tempting to rush this phase of familiarisation and immediately start generating codes and themes; however, this process of immersion will aid researchers in identifying possible themes and patterns. Reading and re-reading the material until the researcher is comfortable is crucial to the initial phase of analysis. While becoming familiar with the material, note-taking is a crucial part of this step in order begin developing potential codes.


==== Transcription ====
After completing data collection, the researcher may need to transcribe their data into written form (e.g. audio recorded data such as interviews). Braun and Clarke provide a transcription notation system for use with their approach in their textbook Successful Qualitative Research. Quality transcription of the data is imperative to the dependability of analysis. Criteria for transcription of data must be established before the transcription phase is initiated to ensure that dependability is high. 
Some thematic analysis proponents – particular those with a foothold in positivism – express concern about the accuracy of transcription. Inconsistencies in transcription can produce 'biases' in data analysis that will be difficult to identify later in the analysis process. For others, including Braun and Clarke, transcription is viewed as an interpretative and theoretically embedded process and therefore cannot be 'accurate' in a straightforward sense, as the researcher always makes choices about how to translate spoken into written text. However, this does not mean that researchers should not strive for thoroughness in their transcripts and use a systematic approach to transcription. Authors should ideally provide a key for their system of transcription notation so it is readily apparent what particular notations mean. Inserting comments like "*voice lowered*" will signal a change in the speech. A general rough guideline to follow when planning time for transcribing is to allow for spending 15 minutes of transcription for every 5 minutes of dialog. Transcription can form part of the familiarisation process.
After this stage, the researcher should feel familiar with the content of the data and should be able to start to identify overt patterns or repeating issues the data. These patterns should be recorded in a reflexivity journal where they will be of use when coding data. Other TA proponents conceptualise coding as the researcher beginning to gain control over the data. They view it as important to mark data that addresses the research question. For them, this is the beginning of the coding process.


=== Phase 2: Generating codes ===
The second step in reflexive thematic analysis is tagging items of interest in the data with a label (a few words or a short phrase). This label should clearly evoke the relevant features of the data – this is important for later stages of theme development. This systematic way of organizing and identifying meaningful parts of data as it relates to the research question is called coding. The coding process evolves through the researcher's immersion in their data and is not considered to be a linear process, but a cyclical process in which codes are developed and refined. 
The coding process is rarely completed from one sweep through the data. Saladana recommends that each time researchers work through the data set, they should strive to refine codes by adding, subtracting, combining or splitting potential codes. For Miles and Huberman, "start codes" are produced through terminology used by participants during the interview and can be used as a reference point of their experiences during the interview. For more positivist inclined thematic analysis proponents, dependability increases when the researcher uses concrete codes that are based on dialogue and are descriptive in nature. These codes will facilitate the researcher's ability to locate pieces of data later in the process and identify why they included them. However, Braun and Clarke urge researchers to look beyond a sole focus on description and summary and engage interpretatively with data – exploring both overt (semantic) and implicit (latent) meaning.  Coding sets the stage for detailed analysis later by allowing the researcher to reorganize the data according to the ideas that have been obtained throughout the process. Reflexivity journal entries for new codes serve as a reference point to the participant and their data section, reminding the researcher to understand why and where they will include these codes in the final analysis. Throughout the coding process, full and equal attention needs to be paid to each data item because it will help in the identification of otherwise unnoticed repeated patterns. Coding as inclusively as possible is important – coding individual aspects of the data that may seem irrelevant can potentially be crucial later in the analysis process.
For sociologists Coffey and Atkinson, coding also involves the process of data reduction and complication. Reduction of codes is initiated by assigning tags or labels to the data set based on the research question(s). In this stage, condensing large data sets into smaller units permits further analysis of the data by creating useful categories. In-vivo codes are also produced by applying references and terminology from the participants in their interviews. Coding aids in development, transformation and re-conceptualization of the data and helps to find more possibilities for analysis. Researchers should ask questions related to the data and generate theories from the data, extending past what has been previously reported in previous research.


==== Data reduction (Coffey and Atkinson) ====
Source:
For some thematic analysis proponents, coding can be thought of as a means of reduction of data or data simplification (this is not the case for Braun and Clarke who view coding as both data reduction and interpretation). For Coffey and Atkinson, using simple but broad analytic codes it is possible to reduce the data to a more manageable feat. In this stage of data analysis the analyst must focus on the identification of a more simple way of organizing data. using data reductionism researchers should include a process of indexing the data texts which could include: field notes, interview transcripts, or other documents. Data at this stage are reduced to classes or categories in which the researcher is able to identify segments of the data that share a common category or code. Siedel and Kelle suggested three ways to aid with the process of data reduction and coding: (a) noticing relevant phenomena, (b) collecting examples of the phenomena, and (c) analyzing phenomena to find similarities, differences, patterns and overlying structures. This aspect of data coding is important because during this stage researchers should be attaching codes to the data to allow the researcher to think about the data in different ways. Coding can not be viewed as strictly data reduction, data complication can be used as a way to open up the data to examine further. The below section addresses Coffey and Atkinson's process of data complication and its significance to data analysis in qualitative analysis.


==== Data complication (Coffey and Atkinson) ====
For Coffey and Atkinson, the process of creating codes can be described as both data reduction and data complication. Data complication can be described as going beyond the data and asking questions about the data to generate frameworks and theories. The complication of data is used to expand on data to create new questions and interpretation of the data. Researchers should make certain that the coding process does not lose more information than is gained. Tesch defined data complication as the process of reconceptualizing the data giving new contexts for the data segments. Data complication serves as a means of providing new contexts for the way data is viewed and analyzed.
Coding is a process of breaking data up through analytical ways and in order to produce questions about the data, providing temporary answers about relationships within and among the data. Decontextualizing and recontextualizing help to reduce and expand the data in new ways with new theories.


=== Phase 3: Generating initial themes ===
Searching for themes and considering what works and what does not work within themes enables the researcher to begin the analysis of potential codes. In this phase, it is important to begin by examining how codes combine to form over-reaching themes in the data. At this point, researchers have a list of themes and begin to focus on broader patterns in the data, combining coded data with proposed themes. Researchers also begin considering how relationships are formed between codes and themes and between different levels of existing themes. It may be helpful to use visual models to sort codes into the potential themes.
Themes differ from codes in that themes are phrases or sentences that identifies what the data means. They describe an outcome of coding for analytic reflection. Themes consist of ideas and descriptions within a culture that can be used to explain causal events, statements, and morals derived from the participants' stories. In subsequent phases, it is important to narrow down the potential themes to provide an overreaching theme. Thematic analysis allows for categories or themes to emerge from the data like the following: repeating ideas; indigenous terms, metaphors and analogies; shifts in topic; and similarities and differences of participants' linguistic expression. It is important at this point to address not only what is present in data, but also what is missing from the data. conclusion of this phase should yield many candidate themes collected throughout the data process.  It is crucial to avoid discarding themes even if they are initially insignificant as they may be important themes later in the analysis process.


=== Phase 4: Reviewing themes ===
This phase requires the researchers to check their initial themes against the coded data and the entire data-set – this is to ensure the analysis hasn't drifted too far from the data and provides a compelling account of the data relevant to the research question. This process of review also allows for further expansion on and revision of themes as they develop. At this point, researchers should have a set of potential themes, as this phase is where the reworking of initial themes takes place. Some existing themes may collapse into each other, other themes may need to be condensed into smaller units, or let go of all together.
Specifically, this phase involves two levels of refining and reviewing themes. Connections between overlapping themes may serve as important sources of information and can alert researchers to the possibility of new patterns and issues in the data. For Guest and colleagues, deviations from coded material can notify the researcher that a theme may not actually be useful to make sense of the data and should be discarded. Both of this acknowledgements should be noted in the researcher's reflexivity journal, also including the absence of themes. Codes serve as a way to relate data to a person's conception of that concept.  At this point, the researcher should focus on interesting aspects of the codes and why they fit together.


==== Level 1 (Reviewing the themes against the coded data) ====
Reviewing coded data extracts allows researchers to identify if themes form coherent patterns. If this is the case, researchers should move onto Level 2. If themes do not form coherent patterns, consideration of the potentially problematic themes is necessary.  If themes are problematic, it is important to rework the theme and during the process, new themes may develop. For example, it is problematic when themes do not appear to 'work' (capture something compelling about the data) or there is a significant amount of overlap between themes. This can result in a weak or unconvincing analysis of the data. If this occurs, data may need to be recognized in order to create cohesive, mutually exclusive themes.


==== Level 2 (Reviewing the themes against the entire data-set) ====
Considering the validity of individual themes and how they connect to the data set as a whole is the next stage of review. It is imperative to assess whether the potential thematic map meaning captures the important information in the data relevant to the research question. Once again, at this stage it is important to read and re-read the data to determine if current themes relate back to the data set. To assist in this process it is imperative to code any additional items that may have been missed earlier in the initial coding stage. If the potential map 'works' to meaningfully capture and tell a coherent story about the data then the researcher should progress to the next phase of analysis. If the map does not work it is crucial to return to the data in order to continue to review and refine existing themes and perhaps even undertake further coding. Mismatches between data and analytic claims reduce the amount of support that can be provided by the data. This can be avoided if the researcher is certain that their interpretations of the data and analytic insights correspond. Researchers repeat this process until they are satisfied with the thematic map. By the end of this phase, researchers have an idea of what themes are and how they fit together so that they convey a story about the data set.


=== Phase 5: Defining and naming themes ===
Defining and refining existing themes that will be presented in the final analysis assists the researcher in analyzing the data within each theme. At this phase, identification of the themes' essences relate to how each specific theme forms part of the entire picture of the data. Analysis at this stage is characterized by identifying which aspects of data are being captured and what is interesting about the themes, and how the themes fit together to tell a coherent and compelling story about the data.
In order to identify whether current themes contain sub-themes and to discover further depth of themes, it is important to consider themes within the whole picture and also as autonomous themes. Braun and Clarke recommend caution about developing many sub-themes and many levels of themes as this may lead to an overly fragmented analysis. Researchers must then conduct and write a detailed analysis to identify the story of each theme and its significance. By the end of this phase, researchers can (1) define what current themes consist of, and (2) explain each theme in a few sentences. It is important to note that researchers begin thinking about names for themes that will give the reader a full sense of the theme and its importance. Failure to fully analyze the data occurs when researchers do not use the data to support their analysis beyond simply describing or paraphrasing the content of the data. Researchers conducting thematic analysis should attempt to go beyond surface meanings of the data to make sense of the data and tell an accurate story of what the data means.


=== Phase 6: Producing the report ===
After final themes have been reviewed, researchers begin the process of writing the final report. While writing the final report, researchers should decide on themes that make meaningful contributions to answering research questions which should be refined later as final themes. For coding reliability proponents Guest and colleagues, researchers present the dialogue connected with each theme in support of increasing dependability through a thick description of the results. The goal of this phase is to write the thematic analysis to convey the complicated story of the data in a manner that convinces the reader of the validity and merit of your analysis. A clear, concise, and straightforward logical account of the story across and with themes is important for readers to understand the final report. The write up of the report should contain enough evidence that themes within the data are relevant to the data set. Extracts should be included in the narrative to capture the full meaning of the points in analysis. The argument should be in support of the research question. For some thematic analysis proponents, the final step in producing the report is to include member checking as a means to establish credibility, researchers should consider taking final themes and supporting dialog to participants to elicit feedback. However, Braun and Clarke are critical of the practice of member checking and do not generally view it as a desirable practice in their reflexive approach to thematic analysis. As well as highlighting numerous practical concerns around member checking, they argue that it is only theoretically coherent with approaches that seek to describe and summarise participants' accounts in ways that would be recognisable to them. Given their reflexive thematic analysis approach centres the active, interpretive role of the researcher – this may not apply to analyses generated using their approach.


== Advantages and disadvantages ==
A technical or pragmatic view of research design centres researchers conducting qualitative analysis using the most appropriate method for the research question. However, there is rarely only one ideal or suitable method so other criteria for selecting methods of analysis are often used – the researcher's theoretical commitments and their familiarity with particular methods. Thematic analysis provides a flexible method of data analysis and allows for researchers with various methodological backgrounds to engage in this type of analysis. For positivists, 'reliability' is a concern because of the numerous potential interpretations of data possible and the potential for researcher subjectivity to 'bias' or distort the analysis. For those committed to qualitative research values, researcher subjectivity is viewed as a resource (rather than a threat to credibility), and so concerns about reliability do not hold. There is no one correct or accurate interpretation of data, interpretations are inevitably subjective and reflect the positioning of the researcher. Quality is achieved through a systematic and rigorous approach and through the researcher continually reflecting on how they are shaping the developing analysis. Braun and Clarke have developed a 15-point quality checklist for their reflexive approach. For coding reliability thematic analysis proponents, the use of multiple coders and the measurement of coding agreement is vital. 
Thematic analysis has several advantages and disadvantages, it is up to the researchers to decide if this method of analysis is suitable for their research design.


=== Advantages ===
The theoretical and research design flexibility it allows researchers – multiple theories can be applied to this process across a variety of epistemologies.
Well suited to large data sets.
Code book and coding reliability approaches are designed for use with research teams.
Interpretation of themes supported by data.
Applicable to research questions that go beyond an individual's experience.
Allows for inductive development of codes and themes from data.


=== Disadvantages ===
Thematic analysis may miss nuanced data if the researcher is not careful and uses thematic analysis in a theoretical vacuum.
Flexibility can make it difficult for novice researchers to decide what aspects of the data to focus on.
Limited interpretive power of analysis is not grounded in a theoretical framework.
Difficult to maintain sense of continuity of data in individual accounts because of the focus on identifying themes across data items.
Does not allow researchers to make technical claims about language usage (unlike discourse analysis and narrative analysis).


== See also ==


== References ==


== External links ==
Thematic Analysis – The University of Auckland
Victoria Clarke's YouTube lecture mapping out different approaches to thematic analysis
Virginia Braun and Victoria Clarke's YouTube lecture providing an introduction to their approach to thematic analysis